[
  {
    "chunk_id": "fast_mcp_api_python:python-sdk:Client_Examples:chunk:0",
    "content": "This document provides practical examples of MCP client implementations, focusing on real-world usage patterns and architectures. The primary example is the simple-chatbot client that demonstrates comprehensive integration with MCP servers, LLM providers, and user interaction patterns.\nFor server-side examples, see\n[Server Examples](#9.1)\n. For core client framework documentation, see\n[Client Framework](#3)\n.",
    "metadata": {
      "source": "python-sdk\\Client_Examples.md",
      "file_name": "Client_Examples.md",
      "subfolder": "python-sdk",
      "chunk_index": 0,
      "total_chunks": 16,
      "char_count": 412,
      "collection": "fast_mcp_api_python",
      "processing_method": "hybrid_chunker",
      "timestamp": "2025-10-15T07:13:09.407366"
    }
  },
  {
    "chunk_id": "fast_mcp_api_python:python-sdk:Client_Examples:chunk:1",
    "content": "The simple-chatbot example demonstrates a complete MCP client implementation that connects to multiple MCP servers, discovers their tools, and integrates with an LLM provider to create an interactive chatbot experience.\n```\ngraph TB\n    subgraph \"Simple Chatbot Architecture\"\n        Config[\"Configuration<br/>Environment & Config Management\"]\n        ChatSession[\"ChatSession<br/>Main Orchestrator\"]\n        LLMClient[\"LLMClient<br/>Groq API Integration\"]\n        \n        subgraph \"Server Management\"\n            Server1[\"Server<br/>MCP Server Connection 1\"]\n            Server2[\"Server<br/>MCP Server Connection 2\"]\n            ServerN[\"Server<br/>MCP Server Connection N\"]\n        end\n        \n        subgraph \"MCP Integration\"\n            ClientSession[\"ClientSession<br/>MCP Protocol Handler\"]\n            StdioTransport[\"stdio_client<br/>Process Communication\"]\n            StdioParams[\"StdioServerParameters<br/>Server Configuration\"]\n        end\n        \n        subgraph \"Tool System\"\n            ToolDiscovery[\"list_tools()<br/>Tool Discovery\"]\n            ToolExecution[\"call_tool()<br/>Tool Execution\"]\n            ToolFormatting[\"Tool.format_for_llm()<br/>LLM Integration\"]\n        end\n    end\n    \n    Config --> ChatSession\n    ChatSession --> LLMClient\n    ChatSession --> Server1\n    ChatSession --> Server2\n    ChatSession --> ServerN\n    \n    Server1 --> ClientSession\n    Server2 --> ClientSession\n    ServerN --> ClientSession\n    \n    ClientSession --> StdioTransport\n    StdioTransport --> StdioParams\n    \n    Server1 --> ToolDiscovery\n    Server1 --> ToolExecution\n    ToolDiscovery --> ToolFormatting\n    \n    LLMClient --> ToolExecution\n```\nSources:\n[examples/clients/simple-chatbot/mcp_simple_chatbot/main.py:1-409](.)",
    "metadata": {
      "source": "python-sdk\\Client_Examples.md",
      "file_name": "Client_Examples.md",
      "subfolder": "python-sdk",
      "chunk_index": 1,
      "total_chunks": 16,
      "char_count": 1748,
      "collection": "fast_mcp_api_python",
      "processing_method": "hybrid_chunker",
      "timestamp": "2025-10-15T07:13:09.407383"
    }
  },
  {
    "chunk_id": "fast_mcp_api_python:python-sdk:Client_Examples:chunk:2",
    "content": "The simple-chatbot demonstrates four main architectural components that work together to provide a complete MCP client experience.",
    "metadata": {
      "source": "python-sdk\\Client_Examples.md",
      "file_name": "Client_Examples.md",
      "subfolder": "python-sdk",
      "chunk_index": 2,
      "total_chunks": 16,
      "char_count": 130,
      "collection": "fast_mcp_api_python",
      "processing_method": "hybrid_chunker",
      "timestamp": "2025-10-15T07:13:09.407391"
    }
  },
  {
    "chunk_id": "fast_mcp_api_python:python-sdk:Client_Examples:chunk:3",
    "content": "The\n```\nConfiguration\n```\nclass handles environment setup and server configuration loading:\n```\ngraph LR\n    subgraph \"Configuration System\"\n        LoadEnv[\"load_env()<br/>Environment Variables\"]\n        LoadConfig[\"load_config()<br/>JSON Configuration\"]\n        APIKey[\"llm_api_key<br/>LLM Provider Access\"]\n    end\n    \n    EnvFile[\".env File\"] --> LoadEnv\n    ConfigJSON[\"servers_config.json\"] --> LoadConfig\n    LoadEnv --> APIKey\n```\nThe configuration system supports:\n- Environment variable management via `python-dotenv`\n- JSON-based server configuration loading\n- API key validation and access\nSources:\n[examples/clients/simple-chatbot/mcp_simple_chatbot/main.py:18-61](.)",
    "metadata": {
      "source": "python-sdk\\Client_Examples.md",
      "file_name": "Client_Examples.md",
      "subfolder": "python-sdk",
      "chunk_index": 3,
      "total_chunks": 16,
      "char_count": 681,
      "collection": "fast_mcp_api_python",
      "processing_method": "hybrid_chunker",
      "timestamp": "2025-10-15T07:13:09.407397"
    }
  },
  {
    "chunk_id": "fast_mcp_api_python:python-sdk:Client_Examples:chunk:4",
    "content": "The\n```\nServer\n```\nclass manages individual MCP server connections with proper lifecycle management:\n```\ngraph TB\n    subgraph \"Server Lifecycle\"\n        Initialize[\"initialize()<br/>Setup Connection\"]\n        Discovery[\"list_tools()<br/>Tool Discovery\"] \n        Execution[\"execute_tool()<br/>Tool Execution\"]\n        Cleanup[\"cleanup()<br/>Resource Management\"]\n    end\n    \n    subgraph \"Transport Layer\"\n        StdioParams[\"StdioServerParameters<br/>command, args, env\"]\n        StdioClient[\"stdio_client()<br/>Process Transport\"]\n        ClientSession[\"ClientSession<br/>Protocol Handler\"]\n    end\n    \n    Initialize --> StdioParams\n    StdioParams --> StdioClient\n    StdioClient --> ClientSession\n    ClientSession --> Discovery\n    ClientSession --> Execution\n    Cleanup --> ClientSession\n```\nKey features include:\n- `AsyncExitStack` for proper resource cleanup\n- Retry logic with configurable attempts and delays\n- Error handling and recovery mechanisms\nSources:\n[examples/clients/simple-chatbot/mcp_simple_chatbot/main.py:63-169](.)",
    "metadata": {
      "source": "python-sdk\\Client_Examples.md",
      "file_name": "Client_Examples.md",
      "subfolder": "python-sdk",
      "chunk_index": 4,
      "total_chunks": 16,
      "char_count": 1045,
      "collection": "fast_mcp_api_python",
      "processing_method": "hybrid_chunker",
      "timestamp": "2025-10-15T07:13:09.407403"
    }
  },
  {
    "chunk_id": "fast_mcp_api_python:python-sdk:Client_Examples:chunk:5",
    "content": "The client demonstrates proper MCP session establishment and management patterns:\n```\nsequenceDiagram\n    participant Client as \"ChatSession\"\n    participant Server as \"Server\"\n    participant Transport as \"stdio_client\"\n    participant Session as \"ClientSession\"\n    participant Process as \"MCP Server Process\"\n    \n    Client->>Server: initialize()\n    Server->>Transport: stdio_client(server_params)\n    Transport->>Process: spawn command + args\n    Transport-->>Server: read, write streams\n    Server->>Session: ClientSession(read, write)\n    Session->>Process: initialize()\n    Process-->>Session: capabilities response\n    Session-->>Server: initialized session\n    Server-->>Client: ready for operations\n```\nThe session management includes:\n- Process spawning with `shutil.which()` for command resolution\n- Stream-based communication setup\n- Capability negotiation through `session.initialize()`\n- Proper error handling and cleanup on failure\nSources:\n[examples/clients/simple-chatbot/mcp_simple_chatbot/main.py:74-94](.)",
    "metadata": {
      "source": "python-sdk\\Client_Examples.md",
      "file_name": "Client_Examples.md",
      "subfolder": "python-sdk",
      "chunk_index": 5,
      "total_chunks": 16,
      "char_count": 1028,
      "collection": "fast_mcp_api_python",
      "processing_method": "hybrid_chunker",
      "timestamp": "2025-10-15T07:13:09.407411"
    }
  },
  {
    "chunk_id": "fast_mcp_api_python:python-sdk:Client_Examples:chunk:6",
    "content": "The client implements comprehensive tool management with LLM integration:",
    "metadata": {
      "source": "python-sdk\\Client_Examples.md",
      "file_name": "Client_Examples.md",
      "subfolder": "python-sdk",
      "chunk_index": 6,
      "total_chunks": 16,
      "char_count": 73,
      "collection": "fast_mcp_api_python",
      "processing_method": "hybrid_chunker",
      "timestamp": "2025-10-15T07:13:09.407417"
    }
  },
  {
    "chunk_id": "fast_mcp_api_python:python-sdk:Client_Examples:chunk:7",
    "content": "```\ngraph LR\n    subgraph \"Tool Discovery Flow\"\n        ListTools[\"session.list_tools()\"]\n        ParseResponse[\"Parse ListToolsResult\"]\n        CreateTool[\"Tool(name, description, inputSchema, title)\"]\n        FormatLLM[\"format_for_llm()\"]\n    end\n    \n    ListTools --> ParseResponse\n    ParseResponse --> CreateTool\n    CreateTool --> FormatLLM\n```\nThe discovery process extracts tool metadata and formats it for LLM consumption:\n- Tool name and description\n- JSON schema for input parameters\n- Required vs optional parameter identification\n- Human-readable formatting for LLM prompts\nSources:\n[examples/clients/simple-chatbot/mcp_simple_chatbot/main.py:96-115](.)\n,\n[examples/clients/simple-chatbot/mcp_simple_chatbot/main.py:171-213](.)",
    "metadata": {
      "source": "python-sdk\\Client_Examples.md",
      "file_name": "Client_Examples.md",
      "subfolder": "python-sdk",
      "chunk_index": 7,
      "total_chunks": 16,
      "char_count": 741,
      "collection": "fast_mcp_api_python",
      "processing_method": "hybrid_chunker",
      "timestamp": "2025-10-15T07:13:09.407424"
    }
  },
  {
    "chunk_id": "fast_mcp_api_python:python-sdk:Client_Examples:chunk:8",
    "content": "```\ngraph TB\n    subgraph \"Tool Execution Flow\"\n        Start[\"call_tool(name, arguments)\"]\n        Attempt[\"Execute via session.call_tool()\"]\n        Success[\"Return Result\"]\n        Error[\"Handle Exception\"]\n        Retry[\"Check Retry Count\"]\n        Delay[\"Sleep with Delay\"]\n        Fail[\"Raise Exception\"]\n    end\n    \n    Start --> Attempt\n    Attempt --> Success\n    Attempt --> Error\n    Error --> Retry\n    Retry -->|\"< max_retries\"| Delay\n    Delay --> Attempt\n    Retry -->|\">= max_retries\"| Fail\n```\nThe execution system provides:\n- Configurable retry attempts (default: 2)\n- Exponential backoff with configurable delay\n- Comprehensive error logging\n- Progress reporting for long-running tools\nSources:\n[examples/clients/simple-chatbot/mcp_simple_chatbot/main.py:117-158](.)",
    "metadata": {
      "source": "python-sdk\\Client_Examples.md",
      "file_name": "Client_Examples.md",
      "subfolder": "python-sdk",
      "chunk_index": 8,
      "total_chunks": 16,
      "char_count": 786,
      "collection": "fast_mcp_api_python",
      "processing_method": "hybrid_chunker",
      "timestamp": "2025-10-15T07:13:09.407430"
    }
  },
  {
    "chunk_id": "fast_mcp_api_python:python-sdk:Client_Examples:chunk:9",
    "content": "The client demonstrates how to integrate MCP tools with LLM providers through structured prompting and tool calling protocols.",
    "metadata": {
      "source": "python-sdk\\Client_Examples.md",
      "file_name": "Client_Examples.md",
      "subfolder": "python-sdk",
      "chunk_index": 9,
      "total_chunks": 16,
      "char_count": 126,
      "collection": "fast_mcp_api_python",
      "processing_method": "hybrid_chunker",
      "timestamp": "2025-10-15T07:13:09.407436"
    }
  },
  {
    "chunk_id": "fast_mcp_api_python:python-sdk:Client_Examples:chunk:10",
    "content": "```\nsequenceDiagram\n    participant User as \"User Input\"\n    participant Chat as \"ChatSession\"\n    participant LLM as \"LLMClient\"\n    participant Tools as \"Tool System\"\n    participant Server as \"MCP Server\"\n    \n    User->>Chat: User message\n    Chat->>LLM: get_response(messages)\n    LLM-->>Chat: Response (text or JSON tool call)\n    Chat->>Chat: process_llm_response()\n    \n    alt Tool Call Detected\n        Chat->>Tools: Parse JSON tool call\n        Tools->>Server: execute_tool(name, args)\n        Server-->>Tools: Tool result\n        Tools-->>Chat: Formatted result\n        Chat->>LLM: get_response(with tool result)\n        LLM-->>Chat: Final natural language response\n    else Direct Response\n        Chat->>User: Pass through response\n    end\n```",
    "metadata": {
      "source": "python-sdk\\Client_Examples.md",
      "file_name": "Client_Examples.md",
      "subfolder": "python-sdk",
      "chunk_index": 10,
      "total_chunks": 16,
      "char_count": 757,
      "collection": "fast_mcp_api_python",
      "processing_method": "hybrid_chunker",
      "timestamp": "2025-10-15T07:13:09.407442"
    }
  },
  {
    "chunk_id": "fast_mcp_api_python:python-sdk:Client_Examples:chunk:11",
    "content": "The client implements a JSON-based tool calling protocol:\n```\n{\n    \"tool\": \"tool-name\",\n    \"arguments\": {\n        \"argument-name\": \"value\"\n    }\n}\n```\nThe system message instructs the LLM on tool usage patterns and response formatting, ensuring consistent tool invocation and natural language result processing.\nSources:\n[examples/clients/simple-chatbot/mcp_simple_chatbot/main.py:283-321](.)\n,\n[examples/clients/simple-chatbot/mcp_simple_chatbot/main.py:341-361](.)",
    "metadata": {
      "source": "python-sdk\\Client_Examples.md",
      "file_name": "Client_Examples.md",
      "subfolder": "python-sdk",
      "chunk_index": 11,
      "total_chunks": 16,
      "char_count": 468,
      "collection": "fast_mcp_api_python",
      "processing_method": "hybrid_chunker",
      "timestamp": "2025-10-15T07:13:09.407449"
    }
  },
  {
    "chunk_id": "fast_mcp_api_python:python-sdk:Client_Examples:chunk:12",
    "content": "The simple-chatbot can be configured through a JSON configuration file:\n```\n{\n    \"mcpServers\": {\n        \"filesystem\": {\n            \"command\": \"node\",\n            \"args\": [\"path/to/filesystem-server.js\"],\n            \"env\": {}\n        },\n        \"database\": {\n            \"command\": \"python\",\n            \"args\": [\"-m\", \"database_server\"],\n            \"env\": {\n                \"DB_PATH\": \"/path/to/database\"\n            }\n        }\n    }\n}\n```",
    "metadata": {
      "source": "python-sdk\\Client_Examples.md",
      "file_name": "Client_Examples.md",
      "subfolder": "python-sdk",
      "chunk_index": 12,
      "total_chunks": 16,
      "char_count": 445,
      "collection": "fast_mcp_api_python",
      "processing_method": "hybrid_chunker",
      "timestamp": "2025-10-15T07:13:09.407454"
    }
  },
  {
    "chunk_id": "fast_mcp_api_python:python-sdk:Client_Examples:chunk:13",
    "content": "Required environment variables:\n- `LLM_API_KEY` : API key for the LLM provider (Groq in this example)\nThe client uses\n```\npython-dotenv\n```\nfor environment management, supporting\n```\n.env\n```\nfiles for development.\nSources:\n[examples/clients/simple-chatbot/mcp_simple_chatbot/main.py:397-404](.)",
    "metadata": {
      "source": "python-sdk\\Client_Examples.md",
      "file_name": "Client_Examples.md",
      "subfolder": "python-sdk",
      "chunk_index": 13,
      "total_chunks": 16,
      "char_count": 295,
      "collection": "fast_mcp_api_python",
      "processing_method": "hybrid_chunker",
      "timestamp": "2025-10-15T07:13:09.407460"
    }
  },
  {
    "chunk_id": "fast_mcp_api_python:python-sdk:Client_Examples:chunk:14",
    "content": "The codebase includes several test patterns that demonstrate client usage:",
    "metadata": {
      "source": "python-sdk\\Client_Examples.md",
      "file_name": "Client_Examples.md",
      "subfolder": "python-sdk",
      "chunk_index": 14,
      "total_chunks": 16,
      "char_count": 74,
      "collection": "fast_mcp_api_python",
      "processing_method": "hybrid_chunker",
      "timestamp": "2025-10-15T07:13:09.407466"
    }
  },
  {
    "chunk_id": "fast_mcp_api_python:python-sdk:Client_Examples:chunk:15",
    "content": "```\ngraph LR\n    subgraph \"Test Client Pattern\"\n        TestSetup[\"Test Setup\"]\n        ClientSession[\"create_connected_server_and_client_session\"]\n        Operations[\"list_resources(), read_resource()\"]\n        Assertions[\"Assert Results\"]\n    end\n    \n    TestSetup --> ClientSession\n    ClientSession --> Operations\n    Operations --> Assertions\n```\nThis pattern is used extensively in tests for validating server behavior from a client perspective.\nSources:\n[tests/issues/test_152_resource_mime_type.py:36-61](.)\n,\n[tests/issues/test_141_resource_templates.py:81-114](.)\nThe examples demonstrate comprehensive MCP client implementation patterns, from basic connection management to advanced tool integration with LLM providers, providing a solid foundation for building sophisticated MCP client applications.",
    "metadata": {
      "source": "python-sdk\\Client_Examples.md",
      "file_name": "Client_Examples.md",
      "subfolder": "python-sdk",
      "chunk_index": 15,
      "total_chunks": 16,
      "char_count": 812,
      "collection": "fast_mcp_api_python",
      "processing_method": "hybrid_chunker",
      "timestamp": "2025-10-15T07:13:09.407471"
    }
  }
]