{
  "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
  "title": "#### On this page",
  "num_chunks": 18,
  "total_chars": 17756,
  "chunks": [
    {
      "index": 0,
      "text": "On this page\n- [Connect](\\docs\\setup\\connect#connect)\n- [Minimum requirements](\\docs\\setup\\connect#minimum-requirements)\n- [Language](\\docs\\setup\\connect#language)\n- [Runtime](\\docs\\setup\\connect#runtime)\n- [Getting started](\\docs\\setup\\connect#getting-started)\n- [How does it work?](\\docs\\setup\\connect#how-does-it-work)\n- [Local development](\\docs\\setup\\connect#local-development)\n- [Deploying to production](\\docs\\setup\\connect#deploying-to-production)\n- [Lifecycle](\\docs\\setup\\connect#lifecycle)\n- [Worker observability](\\docs\\setup\\connect#worker-observability)\n- [Syncing and Rollbacks](\\docs\\setup\\connect#syncing-and-rollbacks)\n- [Health checks](\\docs\\setup\\connect#health-checks)\n- [Kubernetes readiness probe](\\docs\\setup\\connect#kubernetes-readiness-probe)\n- [Self hosted Inngest](\\docs\\setup\\connect#self-hosted-inngest)\n- [Migrating from serve](\\docs\\setup\\connect#migrating-from-serve)\n- [Developer preview](\\docs\\setup\\connect#developer-preview)\n- [Limitations](\\docs\\setup\\connect#limitations)\nPlatform\n[Deployment](\\docs\\platform\\deployment)",
      "char_count": 1059,
      "token_count": 305,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "file_name": "setup_connect.md",
        "file_size": 18647,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "400e7a8301e5289b0b5076f39f161abe9c06d893ea653a4cdaee3915c885e6f8",
        "author": null,
        "created_at": "2025-10-13T00:01:43.642701",
        "modified_at": "2025-10-13T00:01:43.642701",
        "page_count": null,
        "word_count": 2677,
        "extracted_at": "2025-10-13T20:05:12.589731",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 18,
        "token_count": 305,
        "has_context": true
      }
    },
    {
      "index": 1,
      "text": "Connect\nThese docs are part of a developer preview for Inngest's\n```\nconnect\n```\nAPI. Learn more about the\n[developer preview here](\\docs\\setup\\connect#developer-preview)\n.\nThe\n```\nconnect\n```\nAPI allows your app to create an outbound persistent connection to Inngest. Each app can establish multiple connections to Inngest, which enable you to scale horizontally across multiple workers. The key benefits of using\n```\nconnect\n```\ncompared to\n[```\nserve\n```](\\docs\\learn\\serving-inngest-functions)\nare:\n- **Lowest latency** - Persistent connections enable the lowest latency between your app and Inngest.\n- **Elastic horizontal scaling** - Easily add more capacity by running additional workers.\n- **Ideal for container runtimes** - Deploy on Kubernetes or ECS without the need of a load balancer for inbound traffic\n- **Simpler long running steps** - Step execution is not bound by platform http timeouts.",
      "char_count": 906,
      "token_count": 209,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "file_name": "setup_connect.md",
        "file_size": 18647,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "400e7a8301e5289b0b5076f39f161abe9c06d893ea653a4cdaee3915c885e6f8",
        "author": null,
        "created_at": "2025-10-13T00:01:43.642701",
        "modified_at": "2025-10-13T00:01:43.642701",
        "page_count": null,
        "word_count": 2677,
        "extracted_at": "2025-10-13T20:05:12.589731",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 18,
        "token_count": 209,
        "has_context": true
      }
    },
    {
      "index": 2,
      "text": "Connect\nMinimum requirements\nLanguage\n- **TypeScript** : SDK `3.34.1` or higher.\n- **Go** : SDK `0.11.2` or higher.\n- \n**Python**\n: SDK\n```\n0.5.0\n```\nor higher.\n- Install the SDK with `pip install inngest[connect]` since there are additional dependencies required.\n- We also recommend the following constraints:\n- protobuf>=5.29.4,<6.0.0\n- psutil>=6.0.0,<7.0.0\n- websockets>=15.0.0,<16.0.0",
      "char_count": 389,
      "token_count": 142,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "file_name": "setup_connect.md",
        "file_size": 18647,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "400e7a8301e5289b0b5076f39f161abe9c06d893ea653a4cdaee3915c885e6f8",
        "author": null,
        "created_at": "2025-10-13T00:01:43.642701",
        "modified_at": "2025-10-13T00:01:43.642701",
        "page_count": null,
        "word_count": 2677,
        "extracted_at": "2025-10-13T20:05:12.589731",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 18,
        "token_count": 142,
        "has_context": true
      }
    },
    {
      "index": 3,
      "text": "Connect\nMinimum requirements\nRuntime\nYou must use a long running server (Render, Fly.io, Kubernetes, etc.). Serverless runtimes (AWS Lambda, Vercel, etc.) are not supported.\nIf using TypeScript, your runtime must support built-in WebSocket support (Node\n```\n22.4.0\n```\nor higher, Deno\n```\n1.4\n```\nor higher, Bun\n```\n1.1\n```\nor higher).",
      "char_count": 335,
      "token_count": 98,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "file_name": "setup_connect.md",
        "file_size": 18647,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "400e7a8301e5289b0b5076f39f161abe9c06d893ea653a4cdaee3915c885e6f8",
        "author": null,
        "created_at": "2025-10-13T00:01:43.642701",
        "modified_at": "2025-10-13T00:01:43.642701",
        "page_count": null,
        "word_count": 2677,
        "extracted_at": "2025-10-13T20:05:12.589731",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 18,
        "token_count": 98,
        "has_context": true
      }
    },
    {
      "index": 4,
      "text": "Connect\nGetting started\nUsing\n```\nconnect\n```\nwith your app is simple. Using each SDK's \"connect\" method only requires a list of functions that are available to be executed. (Note: Python support is in beta;\n[upvote on our roadmap](https://roadmap.inngest.com/roadmap?id=2bac8d74-288f-47c7-8afc-3fd1a0e94654)\n)\nHere is a one-file example of a fully-functioning app that connects to Inngest.\nTypeScript Go Python\nCopy Copied\n```\nimport { Inngest } from 'inngest'\nimport { connect } from 'inngest/connect' ;\nimport { ConnectionState } from 'inngest/components/connect/types' ;\n\nconst inngest = new Inngest ({\nid : 'my-app'\n});\n\nconst handleSignupFunction = inngest .createFunction (\n{ id : 'handle-signup' } ,\n{ event : 'user.created' }\nasync ({ event , step }) => {\nconsole .log ( 'Function called' , event);\n}\n);\n\n( async () => {\nconst connection = await connect ({\napps : [{ client : inngest , functions : [handleSignupFunction] }]\n});\n\nconsole .log ( 'Worker: connected' , connection);\n})();\n```",
      "char_count": 997,
      "token_count": 281,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "file_name": "setup_connect.md",
        "file_size": 18647,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "400e7a8301e5289b0b5076f39f161abe9c06d893ea653a4cdaee3915c885e6f8",
        "author": null,
        "created_at": "2025-10-13T00:01:43.642701",
        "modified_at": "2025-10-13T00:01:43.642701",
        "page_count": null,
        "word_count": 2677,
        "extracted_at": "2025-10-13T20:05:12.589731",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 18,
        "token_count": 281,
        "has_context": true
      }
    },
    {
      "index": 5,
      "text": "Connect\nHow does it work?\nThe\n```\nconnect\n```\nAPI establishes a persistent WebSocket connection to Inngest. Each connection can handle executing multiple functions and steps concurrently. Each app can create multiple connections to Inngest enabling horizontal scaling. Additionally, connect has the following features:\n- **Automatic re-connections** - The connection will automatically reconnect if it is closed.\n- **Graceful shutdown** - The connection will gracefully shutdown when the app receives a signal to terminate ( `SIGTERM` ). New steps will not be accepted after the connection is closed, and existing steps will be allowed to complete.\n- **Worker-level maximum concurrency (Coming soon)** - Each worker can configure the maximum number of concurrent steps it can handle. This allows Inngest to distribute load across multiple workers and not overload a single worker.",
      "char_count": 880,
      "token_count": 167,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "file_name": "setup_connect.md",
        "file_size": 18647,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "400e7a8301e5289b0b5076f39f161abe9c06d893ea653a4cdaee3915c885e6f8",
        "author": null,
        "created_at": "2025-10-13T00:01:43.642701",
        "modified_at": "2025-10-13T00:01:43.642701",
        "page_count": null,
        "word_count": 2677,
        "extracted_at": "2025-10-13T20:05:12.589731",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 18,
        "token_count": 167,
        "has_context": true
      }
    },
    {
      "index": 6,
      "text": "Connect\nLocal development\nDuring local development, set the\n```\nINNGEST_DEV=1\n```\nenvironment variable to enable local development mode. This will cause the SDK to connect to\n[the Inngest dev server](\\docs\\dev-server)\n. When your worker process is running it will automatically connect to the dev server and sync your functions' configurations.\nNo signing or event keys are required in local development mode.",
      "char_count": 409,
      "token_count": 88,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "file_name": "setup_connect.md",
        "file_size": 18647,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "400e7a8301e5289b0b5076f39f161abe9c06d893ea653a4cdaee3915c885e6f8",
        "author": null,
        "created_at": "2025-10-13T00:01:43.642701",
        "modified_at": "2025-10-13T00:01:43.642701",
        "page_count": null,
        "word_count": 2677,
        "extracted_at": "2025-10-13T20:05:12.589731",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 18,
        "token_count": 88,
        "has_context": true
      }
    },
    {
      "index": 7,
      "text": "Connect\nDeploying to production\nThe\n```\nconnect\n```\nAPI is currently in developer preview and is not yet recommended for critical production workloads. We recommend deploying to a staging environment first prior to deploying to production.\n1\nSet signing and event keys\nTo enable your application to securely connect to Inngest, you must set the\n```\nINNGEST_SIGNING_KEY\n```\nand\n```\nINNGEST_EVENT_KEY\n```\nenvironment variables.\nThese keys can be found in the Inngest Dashboard. Learn more about\n[Event keys](\\docs\\events\\creating-an-event-key)\nand\n[Signing Keys](\\docs\\platform\\signing-keys)\n.\n2\nSet your app version\nThe\n```\nappVersion\n```\nis used to identify the version of your app that is connected to Inngest. This allows Inngest to support rolling deploys where multiple versions of your app may be connected to Inngest.\nWhen a new version of your app is connected to Inngest, the functions' configurations are synced to Inngest. When a new version is connected, Inngest update the function configuration in your environment and starts routing new function runs to the latest version.\nYou can set the\n```\nappVersion\n```\nto whatever you want, but we recommend using something that automatically changes with each deploy, like a git commit sha or Docker image tag.\nAny platform GitHub Actions Render Fly.io\nCopy Copied\n```\n// You can set the app version to any environment variable, you might use\n// a build number ('v2025.02.12.01'), git commit sha ('f5a40ff'), or\n// a custom value ('my-app-v1').\nconst inngest = new Inngest ({\nid : 'my-app' ,\nappVersion : process . env . MY_APP_VERSION , // Use any environment variable you choose\n})\n```\n3\nSet the instance id (recommended)\nThe\n```\ninstanceId\n```\nis used to identify the worker instance of your app that is connected to Inngest. This allows Inngest to support multiple instances (workers) of your app connected to Inngest.\nBy default, Inngest will attempt to use the hostname of the worker as the instance id. If you're running your app in a containerized environment, you can set the\n```\ninstanceId\n```\nto the container id.\nAny platform Kubernetes + Docker Render Fly.io\nCopy Copied\n```\n// Set the instance ID to any environment variable that is unique to the worker\nawait connect ({\napps : [ ... ] ,\ninstanceId : process . env . MY_CONTAINER_ID ,\n})\n```\n4\nSet the max concurrency (recommended)\nThe\n```\nmaxConcurrency\n```\noption is used to limit the number of concurrent steps that can be executed by the worker instance. This allows Inngest to distribute load across multiple workers and not overload a single worker.\nThe\n```\nmaxConcurrency\n```\noption is not yet supported. It will be supported in a future release before general availability.\nCopy Copied\n```\nawait connect ({\napps : [ ... ] ,\nmaxConcurrency : 100 ,\n})\n```",
      "char_count": 2780,
      "token_count": 671,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "file_name": "setup_connect.md",
        "file_size": 18647,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "400e7a8301e5289b0b5076f39f161abe9c06d893ea653a4cdaee3915c885e6f8",
        "author": null,
        "created_at": "2025-10-13T00:01:43.642701",
        "modified_at": "2025-10-13T00:01:43.642701",
        "page_count": null,
        "word_count": 2677,
        "extracted_at": "2025-10-13T20:05:12.589731",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 18,
        "token_count": 671,
        "has_context": true
      }
    },
    {
      "index": 8,
      "text": "Connect\nLifecycle\nAs a connect worker is a long-running process, it's important to understand the lifecycle of the worker and how it relates to the deployment of a new version of your app. Here is an overview of the lifecycle of a connect worker and where you can hook into it to handle graceful shutdowns and other lifecycle events.\n1\n```\nCONNECTING\n```\n- The worker is establishing a connection to Inngest. This starts when\n```\nconnect()\n```\nis called.\nFirst, the worker sends a request to the Inngest API via HTTP to get connection information. The response includes the WebSocket gateway URL. The worker then connects to the WebSocket gateway.\n2\n```\nACTIVE\n```\n- The worker is connected to Inngest and ready to execute functions.\n- The new `appVersion` is synced including the latest function configurations.\n- The worker begins sending and receiving \"heartbeat\" messages to Inngest to ensure the connection is still active.\n- The worker will automatically reconnect if the connection is lost.",
      "char_count": 997,
      "token_count": 211,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "file_name": "setup_connect.md",
        "file_size": 18647,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "400e7a8301e5289b0b5076f39f161abe9c06d893ea653a4cdaee3915c885e6f8",
        "author": null,
        "created_at": "2025-10-13T00:01:43.642701",
        "modified_at": "2025-10-13T00:01:43.642701",
        "page_count": null,
        "word_count": 2677,
        "extracted_at": "2025-10-13T20:05:12.589731",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 18,
        "token_count": 211,
        "has_context": true
      }
    },
    {
      "index": 9,
      "text": "Connect\nLifecycle\nTypeScript\nCopy Copied\n```\n// The connect promise will resolve when the connection is ACTIVE\nconst connection = await connect ({\napps : [ ... ] ,\n})\nconsole .log ( `The worker connection is: ${ connection .state } ` )\n// The worker connection is: ACTIVE\n```\n3\n```\nRECONNECTING\n```\n- The worker is reconnecting to Inngest after a connection was lost.\nThe worker will automatically flush any in-flight steps via the HTTP API when the WebSocket connection is lost.\nBy default, the worker will attempt to reconnect to Inngest an infinite number of times. See the\n[developer preview limitations](\\docs\\setup\\connect#limitations)\nfor more details.\n4\n```\nCLOSING\n```\n- The worker is beginning the shutdown process.\n- New steps will not be accepted after this state is entered.\n- Existing steps will be allowed to complete. The worker will flush any in-flight steps via the HTTP API after the WebSocket connection is closed.\nBy default, the SDK listens for\n```\nSIGTERM\n```\nand\n```\nSIGINT\n```\nsignals and begins the shutdown process. You can customize this behavior by in each SDK:\nTypeScript Go\nCopy Copied\n```\n// You can explicitly configure which signals the SDK should\n// listen for by an array of signals to `handleShutdownSignals`:\nconst connection = await connect ({\napps : [ ... ] ,\n// ex. Only listen for SIGTERM, or pass an empty array to listen to no signals\nhandleShutdownSignals : [ 'SIGTERM' ] ,\n})\n```\nYou can manually close the connection with the\n```\nclose\n```\nmethod on the connection object:\nCopy Copied\n```\nawait connection .close ()\n// Connection is now closed\n```\n5\n```\nCLOSED\n```\n- The worker's WebSocket connection has closed.\nBy this stage, all in-flight steps will be flushed via the HTTP API as the WebSocket connection is closed, ensuring that no in-progress steps are lost.\nCopy Copied\n```\n// The `closed` promise will resolve when the connection is \"CLOSED\"\nawait connection .closed\n// Connection is now closed\n```\n**WebSocket connection and HTTP fallback**\n- While a WebSocket connection is open, the worker will receive and send all step results via the WebSocket connection. When the connection closes, the worker will fallback to the HTTP API to send any remaining step results.",
      "char_count": 2221,
      "token_count": 507,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "file_name": "setup_connect.md",
        "file_size": 18647,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "400e7a8301e5289b0b5076f39f161abe9c06d893ea653a4cdaee3915c885e6f8",
        "author": null,
        "created_at": "2025-10-13T00:01:43.642701",
        "modified_at": "2025-10-13T00:01:43.642701",
        "page_count": null,
        "word_count": 2677,
        "extracted_at": "2025-10-13T20:05:12.589731",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 18,
        "token_count": 507,
        "has_context": true
      }
    },
    {
      "index": 10,
      "text": "Connect\nWorker observability\nIn the Inngest Cloud dashboard, you can view the connection status of each of your workers. At a glance, you can see each worker's instance id, connection status, connected at timestamp, last heartbeat, the app version, and app version.\nThis view is helpful for debugging connection issues or verifying rolling deploys of new app versions.\nApp worker observability",
      "char_count": 393,
      "token_count": 79,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "file_name": "setup_connect.md",
        "file_size": 18647,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "400e7a8301e5289b0b5076f39f161abe9c06d893ea653a4cdaee3915c885e6f8",
        "author": null,
        "created_at": "2025-10-13T00:01:43.642701",
        "modified_at": "2025-10-13T00:01:43.642701",
        "page_count": null,
        "word_count": 2677,
        "extracted_at": "2025-10-13T20:05:12.589731",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 18,
        "token_count": 79,
        "has_context": true
      }
    },
    {
      "index": 11,
      "text": "Connect\nSyncing and Rollbacks\nInngest keeps track of the version your workers are running on. This internal representation changes when you update your function configuration, provide a new app version identifier to the client configuration, or change the SDK version or language.\nWhen you deploy a new version of your application, the first worker to connect to Inngest will automatically sync your app. This will update function configurations to the desired state configured in your code.\n```\nconnect\n```\nsupports rolling releases: During a deployment of your app, Inngest will run functions on all connected workers, regardless of the version, as long as they are able to process a request for a given function. This prevents traffic from concentrating on a single instance during rollouts and causing a thundering herd issue.\nOnce all old workers have terminated after a deployment, you can roll back to an old version by bringing back an old worker. Similar to the deployment process, this will update the function configuration to the previous state and gradually allow you to shift traffic to the old version by bringing up more old workers while terminating workers running the newer version.",
      "char_count": 1201,
      "token_count": 225,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "file_name": "setup_connect.md",
        "file_size": 18647,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "400e7a8301e5289b0b5076f39f161abe9c06d893ea653a4cdaee3915c885e6f8",
        "author": null,
        "created_at": "2025-10-13T00:01:43.642701",
        "modified_at": "2025-10-13T00:01:43.642701",
        "page_count": null,
        "word_count": 2677,
        "extracted_at": "2025-10-13T20:05:12.589731",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 18,
        "token_count": 225,
        "has_context": true
      }
    },
    {
      "index": 12,
      "text": "Connect\nHealth checks\nIf you are running your app in a containerized environment, we recommend using a health check to ensure that your app is running and ready to accept connections. This is key for graceful rollouts of new app versions. If you are using Kubernetes, we recommend using the\n```\nreadinessProbe\n```\nto check that the app is ready to accept connections.\nThe simplest way to implement a health check is to create an http endpoint that listens for health check requests. As connect is an outbound WebSocket connection, you'll need to create a small http server that listens for health check requests and returns a 200 status code when the connection to Inngest is active.\nHere is an example of using\n```\nconnect\n```\nwith a basic Node.js http server to listen for health check requests and return a 200 status code when the connection to Inngest is active.\nNode.js Bun (JavaScript)\nCopy Copied\n```\nimport { createServer } from 'http' ;\nimport { connect } from 'inngest/connect' ;\nimport { ConnectionState } from 'inngest/components/connect/types' ;\nimport { inngest , functions } from './src/inngest' ;\n\n( async () => {\nconst connection = await connect ({\napps : [{ client : inngest , functions }]\n});\n\nconsole .log ( 'Worker: connected' , connection);\n\n// This is a basic web server that only listens for the /ready endpoint\n// and returns a 200 status code when the connection to Inngest is active.\nconst httpServer = createServer ((req , res) => {\nif ( req .url === '/ready' ) {\nif ( connection .state === ConnectionState . ACTIVE ) {\nres .writeHead ( 200 , { 'Content-Type' : 'text/plain' });\nres .end ( 'OK' );\n} else {\nres .writeHead ( 500 , { 'Content-Type' : 'text/plain' });\nres .end ( 'NOT OK' );\n}\nreturn ;\n}\nres .writeHead ( 404 , { 'Content-Type' : 'text/plain' });\nres .end ( 'NOT FOUND' );\n});\n\n// Start the server on a port of your choice\nhttpServer .listen ( 8080 , () => {\nconsole .log ( 'Worker: HTTP server listening on port 8080' );\n});\n\n// When the Inngest connection has gracefully closed,\n// this will resolve and the app will exit.\nawait connection .closed;\nconsole .log ( 'Worker: Shut down' );\n\n// Stop the HTTP server\nhttpServer .close ();\n})();\n```",
      "char_count": 2188,
      "token_count": 548,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "file_name": "setup_connect.md",
        "file_size": 18647,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "400e7a8301e5289b0b5076f39f161abe9c06d893ea653a4cdaee3915c885e6f8",
        "author": null,
        "created_at": "2025-10-13T00:01:43.642701",
        "modified_at": "2025-10-13T00:01:43.642701",
        "page_count": null,
        "word_count": 2677,
        "extracted_at": "2025-10-13T20:05:12.589731",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 18,
        "token_count": 548,
        "has_context": true
      }
    },
    {
      "index": 13,
      "text": "Connect\nHealth checks\nKubernetes readiness probe\nIf you are running your app in Kubernetes, you can use the\n```\nreadinessProbe\n```\nto check that the app is ready to accept connections. For the above example running on port 8080, the readiness probe would look like this:\nCopy Copied\n```\nreadinessProbe :\nhttpGet :\npath : /ready\ninitialDelaySeconds : 3\nperiodSeconds : 10\nsuccessThreshold : 3\nfailureThreshold : 3\n```",
      "char_count": 416,
      "token_count": 109,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "file_name": "setup_connect.md",
        "file_size": 18647,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "400e7a8301e5289b0b5076f39f161abe9c06d893ea653a4cdaee3915c885e6f8",
        "author": null,
        "created_at": "2025-10-13T00:01:43.642701",
        "modified_at": "2025-10-13T00:01:43.642701",
        "page_count": null,
        "word_count": 2677,
        "extracted_at": "2025-10-13T20:05:12.589731",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 18,
        "token_count": 109,
        "has_context": true
      }
    },
    {
      "index": 14,
      "text": "Connect\nSelf hosted Inngest\nSelf-hosting support for\n```\nconnect\n```\nis in development. Please\n[contact us](https://app.inngest.com/support)\nfor more info.\nIf you are\n[self-hosting](\\docs\\self-hosting?ref=docs-connect)\nInngest, you need to ensure that the Inngest WebSocket gateway is accessible within your network. The Inngest WebSocket gateway is available at port\n```\n8289\n```\n.\nDepending on your network configuration, you may need to dynamically re-write the gateway URL that the SDK uses to connect.\nCopy Copied\n```\nconst connection = await connect ({\napps : [ ... ] ,\nrewriteGatewayEndpoint : (url) => { // ex. \"wss://gw2.connect.inngest.com/v0/connect\"\n// If not running in dev mode, return\nif ( ! process . env . INNGEST_DEV ) {\nconst clusterUrl = new URL (url);\nclusterUrl .host = 'my-cluster-host:8289' ;\nreturn clusterUrl .toString ();\n}\nreturn url;\n} ,\n})\n```",
      "char_count": 873,
      "token_count": 235,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "file_name": "setup_connect.md",
        "file_size": 18647,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "400e7a8301e5289b0b5076f39f161abe9c06d893ea653a4cdaee3915c885e6f8",
        "author": null,
        "created_at": "2025-10-13T00:01:43.642701",
        "modified_at": "2025-10-13T00:01:43.642701",
        "page_count": null,
        "word_count": 2677,
        "extracted_at": "2025-10-13T20:05:12.589731",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 18,
        "token_count": 235,
        "has_context": true
      }
    },
    {
      "index": 15,
      "text": "Connect\nMigrating from serve\nWe are working on enabling more fine-grained function and app migrations from existing\n```\nserve\n```\napps to\n```\nconnect\n```\n.\nDuring the Inngest developer preview, we recommend setting up a new app for trying out\n```\nconnect\n```\n. We will support gradually migrating your existing\n```\nserve\n```\napps in a future release.",
      "char_count": 350,
      "token_count": 86,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "file_name": "setup_connect.md",
        "file_size": 18647,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "400e7a8301e5289b0b5076f39f161abe9c06d893ea653a4cdaee3915c885e6f8",
        "author": null,
        "created_at": "2025-10-13T00:01:43.642701",
        "modified_at": "2025-10-13T00:01:43.642701",
        "page_count": null,
        "word_count": 2677,
        "extracted_at": "2025-10-13T20:05:12.589731",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 18,
        "token_count": 86,
        "has_context": true
      }
    },
    {
      "index": 16,
      "text": "Connect\nDeveloper preview\nThe\n```\nconnect\n```\nAPI is currently in developer preview. This means that the API is not yet recommended for critical production workloads and is subject to breaking changes.\nDuring the developer preview, the\n```\nconnect\n```\nAPI is available to all Inngest accounts with the following plan-limits:\n- Free plan: 3 concurrent worker connections\n- All paid plans: 20 concurrent worker connections\n- Max apps per connection: 10\nFinal plan limitations will be announced prior to general availability. Please\n[contact us](https://app.inngest.com/support)\nif you need to increase these limits.\nRead the\n[release phases](\\docs\\release-phases)\nfor more details.",
      "char_count": 679,
      "token_count": 154,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "file_name": "setup_connect.md",
        "file_size": 18647,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "400e7a8301e5289b0b5076f39f161abe9c06d893ea653a4cdaee3915c885e6f8",
        "author": null,
        "created_at": "2025-10-13T00:01:43.642701",
        "modified_at": "2025-10-13T00:01:43.642701",
        "page_count": null,
        "word_count": 2677,
        "extracted_at": "2025-10-13T20:05:12.589731",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 18,
        "token_count": 154,
        "has_context": true
      }
    },
    {
      "index": 17,
      "text": "Connect\nDeveloper preview\nLimitations\nDuring the developer preview, there are some limitations to using\n```\nconnect\n```\nto be aware of. Please\n[contact us](https://app.inngest.com/support)\nif you'd like clarity on any of the following:\n- **Worker-level maximum concurrency** - This is not yet supported. When completed, each worker can configure the maximum number of concurrent steps it can handle. This allows Inngest to distribute load across multiple workers and not overload a single worker.\n- **Reconnection policy is not configurable** - The SDK will attempt to reconnect to Inngest an infinite number of times. We will expose a configurable reconnection policy in the future.",
      "char_count": 683,
      "token_count": 144,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\setup_connect.md",
        "file_name": "setup_connect.md",
        "file_size": 18647,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "400e7a8301e5289b0b5076f39f161abe9c06d893ea653a4cdaee3915c885e6f8",
        "author": null,
        "created_at": "2025-10-13T00:01:43.642701",
        "modified_at": "2025-10-13T00:01:43.642701",
        "page_count": null,
        "word_count": 2677,
        "extracted_at": "2025-10-13T20:05:12.589731",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 18,
        "token_count": 144,
        "has_context": true
      }
    }
  ]
}