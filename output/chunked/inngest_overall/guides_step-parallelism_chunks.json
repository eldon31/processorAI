{
  "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
  "title": "#### On this page",
  "num_chunks": 10,
  "total_chars": 6781,
  "chunks": [
    {
      "index": 0,
      "text": "On this page\n- [Step parallelism](\\docs\\guides\\step-parallelism#step-parallelism)\n- [Platform support](\\docs\\guides\\step-parallelism#platform-support)\n- [Running steps in parallel](\\docs\\guides\\step-parallelism#running-steps-in-parallel)\n- [Step parallelism in Python](\\docs\\guides\\step-parallelism#step-parallelism-in-python)\n- [Chunking jobs](\\docs\\guides\\step-parallelism#chunking-jobs)\n- [Limitations](\\docs\\guides\\step-parallelism#limitations)\n- [Parallelism vs fan-out](\\docs\\guides\\step-parallelism#parallelism-vs-fan-out)\nFeatures\n[Inngest Functions](\\docs\\features\\inngest-functions)\n[Steps & Workflows](\\docs\\features\\inngest-functions\\steps-workflows)",
      "char_count": 662,
      "token_count": 200,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "file_name": "guides_step-parallelism.md",
        "file_size": 7259,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "9ab6057702d17c47ed94f626a29c8c19228083a0b8258d69d2d96dd794361803",
        "author": null,
        "created_at": "2025-10-12T23:59:48.435700",
        "modified_at": "2025-10-12T23:59:48.435833",
        "page_count": null,
        "word_count": 1012,
        "extracted_at": "2025-10-13T20:03:56.414140",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 200,
        "has_context": true
      }
    },
    {
      "index": 1,
      "text": "Step parallelism\n- If you're using a serverless platform to host, code will run in true parallelism similar to multi-threading (without shared state)\n- Each step will be individually retried",
      "char_count": 190,
      "token_count": 41,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "file_name": "guides_step-parallelism.md",
        "file_size": 7259,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "9ab6057702d17c47ed94f626a29c8c19228083a0b8258d69d2d96dd794361803",
        "author": null,
        "created_at": "2025-10-12T23:59:48.435700",
        "modified_at": "2025-10-12T23:59:48.435833",
        "page_count": null,
        "word_count": 1012,
        "extracted_at": "2025-10-13T20:03:56.414140",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 41,
        "has_context": true
      }
    },
    {
      "index": 2,
      "text": "Step parallelism\nPlatform support\n**Parallelism works across all providers and platforms**\n.  True parallelism is supported for serverless functions;  if you're using a single Express server you'll be splitting all parallel jobs amongst a single-threaded node server.",
      "char_count": 267,
      "token_count": 53,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "file_name": "guides_step-parallelism.md",
        "file_size": 7259,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "9ab6057702d17c47ed94f626a29c8c19228083a0b8258d69d2d96dd794361803",
        "author": null,
        "created_at": "2025-10-12T23:59:48.435700",
        "modified_at": "2025-10-12T23:59:48.435833",
        "page_count": null,
        "word_count": 1012,
        "extracted_at": "2025-10-13T20:03:56.414140",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 53,
        "has_context": true
      }
    },
    {
      "index": 3,
      "text": "Step parallelism\nRunning steps in parallel\nYou can run steps in parallel via\n```\nPromise.all()\n```\n:\n- Create each step via [`step.run()`](\\docs\\reference\\functions\\step-run) without awaiting, which returns an unresolved promise.\n- Await all steps via `Promise.all()` . This triggers all steps to run in parallel via separate executions.\nA common use case is to split work into chunks:\nCopy Copied\n```\nimport { Inngest } from \"inngest\" ;\n\nconst inngest = new Inngest ({ id : \"signup-flow\" });\n\nexport const fn = inngest .createFunction (\n{ id : \"post-payment-flow\" } ,\n{ event : \"stripe/charge.created\" } ,\nasync ({ event , step }) => {\n// These steps are not `awaited` and run in parallel when Promise.all\n// is invoked.\nconst sendEmail = step .run ( \"confirmation-email\" , async () => {\nconst emailID = await sendEmail ( event . data .email);\nreturn emailID;\n});\n\nconst updateUser = step .run ( \"update-user\" , async () => {\nreturn db .updateUserWithCharge (event);\n});\n\n// Run both steps in parallel.  Once complete, Promise.all will return all\n// parallelized state here.\n//\n// This ensures that all steps complete as fast as possible, and we still have\n// access to each step's data once they're complete.\nconst [ emailID , updates ] = await Promise .all ([sendEmail , updateUser]);\n\nreturn { emailID , updates };\n}\n);\n```\nWhen each step is finished, Inngest will aggregate each step's state and re-invoke the function with all state available.",
      "char_count": 1449,
      "token_count": 355,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "file_name": "guides_step-parallelism.md",
        "file_size": 7259,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "9ab6057702d17c47ed94f626a29c8c19228083a0b8258d69d2d96dd794361803",
        "author": null,
        "created_at": "2025-10-12T23:59:48.435700",
        "modified_at": "2025-10-12T23:59:48.435833",
        "page_count": null,
        "word_count": 1012,
        "extracted_at": "2025-10-13T20:03:56.414140",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 355,
        "has_context": true
      }
    },
    {
      "index": 4,
      "text": "Step parallelism\nRunning steps in parallel\nStep parallelism in Python\nInngest supports parallel steps regardless of whether you're using asynchronous or synchronous code. For both approaches, you can use\n```\nstep.parallel\n```\n:",
      "char_count": 227,
      "token_count": 48,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "file_name": "guides_step-parallelism.md",
        "file_size": 7259,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "9ab6057702d17c47ed94f626a29c8c19228083a0b8258d69d2d96dd794361803",
        "author": null,
        "created_at": "2025-10-12T23:59:48.435700",
        "modified_at": "2025-10-12T23:59:48.435833",
        "page_count": null,
        "word_count": 1012,
        "extracted_at": "2025-10-13T20:03:56.414140",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 48,
        "has_context": true
      }
    },
    {
      "index": 5,
      "text": "Step parallelism\nRunning steps in parallel\nasync - with inngest.Step and await ctx.group.parallel()\nCopy Copied\n```\n@client . create_function (\nfn_id = \"my-fn\" ,\ntrigger = inngest. TriggerEvent (event = \"my-event\" ),\n)\nasync def fn ( ctx : inngest . Context) -> None :\nuser_id = ctx . event . data [ \"user_id\" ]\n\n(updated_user , sent_email) = await ctx . group . parallel (\n(\nlambda : step. run ( \"update-user\" , update_user, user_id),\nlambda : step. run ( \"send-email\" , send_email, user_id),\n)\n)\n```",
      "char_count": 501,
      "token_count": 141,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "file_name": "guides_step-parallelism.md",
        "file_size": 7259,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "9ab6057702d17c47ed94f626a29c8c19228083a0b8258d69d2d96dd794361803",
        "author": null,
        "created_at": "2025-10-12T23:59:48.435700",
        "modified_at": "2025-10-12T23:59:48.435833",
        "page_count": null,
        "word_count": 1012,
        "extracted_at": "2025-10-13T20:03:56.414140",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 141,
        "has_context": true
      }
    },
    {
      "index": 6,
      "text": "Step parallelism\nRunning steps in parallel\nsync - with inngest.StepSync and group.parallel()\nCopy Copied\n```\n@client . create_function (\nfn_id = \"my-fn\" ,\ntrigger = inngest. TriggerEvent (event = \"my-event\" ),\n)\ndef fn ( ctx : inngest . ContextSync) -> None :\nuser_id = ctx . event . data [ \"user_id\" ]\n\n(updated_user , sent_email) = ctx . group . parallel (\n(\nlambda : ctx.step. run ( \"update-user\" , update_user, user_id),\nlambda : ctx.step. run ( \"send-email\" , send_email, user_id),\n)\n)\n```\nAt this time, Inngest does not have stable support for\n```\nasyncio.gather\n```\nor\n```\nasyncio.wait\n```\n. If you'd like to try out experimental support, use the\n```\n_experimental_execution\n```\noption when creating your function:\nCopy Copied\n```\n@client . create_function (\nfn_id = \"my-fn\" ,\ntrigger = inngest. TriggerEvent (event = \"my-event\" ),\n_experimental_execution = True ,\n)\ndef fn ( ctx : inngest . ContextSync) -> None :\nuser_id = ctx . event . data [ \"user_id\" ]\n\n(updated_user , sent_email) = asyncio . gather (\nasyncio. create_task (ctx.step. run ( \"update-user\" , update_user, user_id)),\nasyncio. create_task (ctx.step. run ( \"send-email\" , send_email, user_id)),\n)\n```\nWhen using\n```\nasyncio.wait\n```\n,\n```\nasyncio.FIRST_COMPLETED\n```\nis supported. However,\n```\nasyncio.FIRST_EXCEPTION\n```\nis not supported due to the way Inngest interrupts the execution of the function.",
      "char_count": 1377,
      "token_count": 388,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "file_name": "guides_step-parallelism.md",
        "file_size": 7259,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "9ab6057702d17c47ed94f626a29c8c19228083a0b8258d69d2d96dd794361803",
        "author": null,
        "created_at": "2025-10-12T23:59:48.435700",
        "modified_at": "2025-10-12T23:59:48.435833",
        "page_count": null,
        "word_count": 1012,
        "extracted_at": "2025-10-13T20:03:56.414140",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 388,
        "has_context": true
      }
    },
    {
      "index": 7,
      "text": "Step parallelism\nChunking jobs\nA common use case is to chunk work. For example, when using OpenAI's APIs you might need to chunk a user's input and run the API on many chunks, then aggregate all data:\nCopy Copied\n```\nimport { Inngest } from \"inngest\" ;\n\nconst inngest = new Inngest ({ id : \"signup-flow\" });\n\nexport const fn = inngest .createFunction (\n{ id : \"summarize-text\" } ,\n{ event : \"app/text.summarize\" } ,\nasync ({ event , step }) => {\nconst chunks = splitTextIntoChunks ( event . data .text);\n\nconst summaries = await Promise .all (\nchunks .map ((chunk) =>\nstep .run ( \"summarize-chunk\" , () => summarizeChunk (chunk))\n)\n);\n\nawait step .run ( \"summarize-summaries\" , () => summarizeSummaries (summaries));\n}\n);\n```\nThis allows you to run many independent steps, wait until they're all finished, then fetch the results from all steps within a few lines of code. Doing this in a traditional system would require creating many jobs, polling the status of all jobs, and manually combining state.",
      "char_count": 1002,
      "token_count": 257,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "file_name": "guides_step-parallelism.md",
        "file_size": 7259,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "9ab6057702d17c47ed94f626a29c8c19228083a0b8258d69d2d96dd794361803",
        "author": null,
        "created_at": "2025-10-12T23:59:48.435700",
        "modified_at": "2025-10-12T23:59:48.435833",
        "page_count": null,
        "word_count": 1012,
        "extracted_at": "2025-10-13T20:03:56.414140",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 257,
        "has_context": true
      }
    },
    {
      "index": 8,
      "text": "Step parallelism\nLimitations\nCurrently, the total data returned from\n**all**\nsteps must be under 4MB (eg. a single step can return a max of. 4MB, or 4 steps can return a max of 1MB each).  Functions are also limited to a maximum of 1,000 steps.",
      "char_count": 244,
      "token_count": 72,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "file_name": "guides_step-parallelism.md",
        "file_size": 7259,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "9ab6057702d17c47ed94f626a29c8c19228083a0b8258d69d2d96dd794361803",
        "author": null,
        "created_at": "2025-10-12T23:59:48.435700",
        "modified_at": "2025-10-12T23:59:48.435833",
        "page_count": null,
        "word_count": 1012,
        "extracted_at": "2025-10-13T20:03:56.414140",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 72,
        "has_context": true
      }
    },
    {
      "index": 9,
      "text": "Step parallelism\nParallelism vs fan-out\nAnother technique similar to parallelism is fan-out (\n[read the guide here](\\docs\\guides\\fan-out-jobs)\n):  when one function sends events to trigger other functions.  Here are the key differences:\n- Both patterns run jobs in parallel\n- You can access the output of steps ran in parallel within your function, whereas with fan-out you cannot\n- Parallelism has a limit of 1,000 steps, though you can create as many functions as you'd like using fan-out\n- You can replay events via fan-out, eg. to test functions locally\n- You can retry individual functions easily if they permanently fail, whereas if a step permanently fails (after retrying) the function itself will fail and terminate.\n- Fan-out splits functionality into different functions, using step functions keeps all related logic in a single, easy to read function",
      "char_count": 862,
      "token_count": 187,
      "metadata": {
        "title": "#### On this page",
        "source": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "chunk_method": "hybrid",
        "file_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\Docs\\inngest_overall\\guides_step-parallelism.md",
        "file_name": "guides_step-parallelism.md",
        "file_size": 7259,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "9ab6057702d17c47ed94f626a29c8c19228083a0b8258d69d2d96dd794361803",
        "author": null,
        "created_at": "2025-10-12T23:59:48.435700",
        "modified_at": "2025-10-12T23:59:48.435833",
        "page_count": null,
        "word_count": 1012,
        "extracted_at": "2025-10-13T20:03:56.414140",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 187,
        "has_context": true
      }
    }
  ]
}