{
  "source": "Docs\\agent_kit\\streaming_usage-guide.md",
  "title": "##### Get Started",
  "num_chunks": 10,
  "total_chars": 20227,
  "chunks": [
    {
      "index": 0,
      "text": "Get Started\n- [Overview](\\overview)\n- [Quick start](\\getting-started\\quick-start)\n- [Installation](\\getting-started\\installation)\n- [Local development](\\getting-started\\local-development)",
      "char_count": 187,
      "token_count": 47,
      "metadata": {
        "title": "##### Get Started",
        "source": "Docs\\agent_kit\\streaming_usage-guide.md",
        "chunk_method": "hybrid",
        "file_path": "Docs\\agent_kit\\streaming_usage-guide.md",
        "file_name": "streaming_usage-guide.md",
        "file_size": 20969,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "25b5391485f54485ee7b3d3e898d1a3dc75e8faf38caa8ca0a69b2dbd765c0ea",
        "author": null,
        "created_at": "2025-10-12T23:52:24.205018",
        "modified_at": "2025-10-12T23:52:24.205618",
        "page_count": null,
        "word_count": 3442,
        "extracted_at": "2025-10-13T20:00:14.311209",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 47,
        "has_context": true
      }
    },
    {
      "index": 1,
      "text": "Concepts\n- [Agents](\\concepts\\agents)\n- [Tools](\\concepts\\tools)\n- [Networks](\\concepts\\networks)\n- [State](\\concepts\\state)\n- [Routers](\\concepts\\routers)\n- [History](\\concepts\\history)\n- [Memory](\\concepts\\memory)\n- [Models](\\concepts\\models)\n- [Deployment](\\concepts\\deployment)",
      "char_count": 281,
      "token_count": 95,
      "metadata": {
        "title": "##### Get Started",
        "source": "Docs\\agent_kit\\streaming_usage-guide.md",
        "chunk_method": "hybrid",
        "file_path": "Docs\\agent_kit\\streaming_usage-guide.md",
        "file_name": "streaming_usage-guide.md",
        "file_size": 20969,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "25b5391485f54485ee7b3d3e898d1a3dc75e8faf38caa8ca0a69b2dbd765c0ea",
        "author": null,
        "created_at": "2025-10-12T23:52:24.205018",
        "modified_at": "2025-10-12T23:52:24.205618",
        "page_count": null,
        "word_count": 3442,
        "extracted_at": "2025-10-13T20:00:14.311209",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 95,
        "has_context": true
      }
    },
    {
      "index": 2,
      "text": "Streaming\n- [Overview](\\streaming\\overview)\n- [Usage Guide](\\streaming\\usage-guide)\n- [Events](\\streaming\\events)\n- [Transport](\\streaming\\transport)\n- [Provider](\\streaming\\provider)",
      "char_count": 183,
      "token_count": 54,
      "metadata": {
        "title": "##### Get Started",
        "source": "Docs\\agent_kit\\streaming_usage-guide.md",
        "chunk_method": "hybrid",
        "file_path": "Docs\\agent_kit\\streaming_usage-guide.md",
        "file_name": "streaming_usage-guide.md",
        "file_size": 20969,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "25b5391485f54485ee7b3d3e898d1a3dc75e8faf38caa8ca0a69b2dbd765c0ea",
        "author": null,
        "created_at": "2025-10-12T23:52:24.205018",
        "modified_at": "2025-10-12T23:52:24.205618",
        "page_count": null,
        "word_count": 3442,
        "extracted_at": "2025-10-13T20:00:14.311209",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 54,
        "has_context": true
      }
    },
    {
      "index": 3,
      "text": "Advanced Patterns\n- [Deterministic state routing](\\advanced-patterns\\routing)\n- [MCP as tools](\\advanced-patterns\\mcp)\n- [Human in the Loop](\\advanced-patterns\\human-in-the-loop)\n- [Multi-steps tools](\\advanced-patterns\\multi-steps-tools)\n- [Configuring Retries](\\advanced-patterns\\retries)\n- [Configuring Multi-tenancy](\\advanced-patterns\\multitenancy)\n- [UI Streaming with useAgent](\\advanced-patterns\\legacy-ui-streaming)",
      "char_count": 424,
      "token_count": 117,
      "metadata": {
        "title": "##### Get Started",
        "source": "Docs\\agent_kit\\streaming_usage-guide.md",
        "chunk_method": "hybrid",
        "file_path": "Docs\\agent_kit\\streaming_usage-guide.md",
        "file_name": "streaming_usage-guide.md",
        "file_size": 20969,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "25b5391485f54485ee7b3d3e898d1a3dc75e8faf38caa8ca0a69b2dbd765c0ea",
        "author": null,
        "created_at": "2025-10-12T23:52:24.205018",
        "modified_at": "2025-10-12T23:52:24.205618",
        "page_count": null,
        "word_count": 3442,
        "extracted_at": "2025-10-13T20:00:14.311209",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 117,
        "has_context": true
      }
    },
    {
      "index": 4,
      "text": "Guided Tour\n- [The three levels of AI apps](\\guided-tour\\overview)\n- [1. Explaining a given code file](\\guided-tour\\ai-workflows)\n- [2. Complex code analysis](\\guided-tour\\agentic-workflows)\n- [3. Autonomous Bug Solver](\\guided-tour\\ai-agents)",
      "char_count": 243,
      "token_count": 75,
      "metadata": {
        "title": "##### Get Started",
        "source": "Docs\\agent_kit\\streaming_usage-guide.md",
        "chunk_method": "hybrid",
        "file_path": "Docs\\agent_kit\\streaming_usage-guide.md",
        "file_name": "streaming_usage-guide.md",
        "file_size": 20969,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "25b5391485f54485ee7b3d3e898d1a3dc75e8faf38caa8ca0a69b2dbd765c0ea",
        "author": null,
        "created_at": "2025-10-12T23:52:24.205018",
        "modified_at": "2025-10-12T23:52:24.205618",
        "page_count": null,
        "word_count": 3442,
        "extracted_at": "2025-10-13T20:00:14.311209",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 75,
        "has_context": true
      }
    },
    {
      "index": 5,
      "text": "Integrations\n- [E2B - Sandboxes for AI Agents](\\integrations\\e2b)\n- [Browserbase - AI Browsers](\\integrations\\browserbase)\n- [Smithery - MCP Registry](\\integrations\\smithery)\nclose\nOn this page\n- [Set up Inngest for streaming](#set-up-inngest-for-streaming)\nStreaming",
      "char_count": 267,
      "token_count": 81,
      "metadata": {
        "title": "##### Get Started",
        "source": "Docs\\agent_kit\\streaming_usage-guide.md",
        "chunk_method": "hybrid",
        "file_path": "Docs\\agent_kit\\streaming_usage-guide.md",
        "file_name": "streaming_usage-guide.md",
        "file_size": 20969,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "25b5391485f54485ee7b3d3e898d1a3dc75e8faf38caa8ca0a69b2dbd765c0ea",
        "author": null,
        "created_at": "2025-10-12T23:52:24.205018",
        "modified_at": "2025-10-12T23:52:24.205618",
        "page_count": null,
        "word_count": 3442,
        "extracted_at": "2025-10-13T20:00:14.311209",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 81,
        "has_context": true
      }
    },
    {
      "index": 6,
      "text": "Usage Guide\nA deep dive into streaming agents\nLet's build a simple SQL generation agent network with realtime streaming. To kick things off, let's walk through a few endpoints you'll need to wire this all up:\n- **Inngest Client (** **`/api/inngest/client.ts`** **)** : Initializes Inngest with the `realtimeMiddleware` .\n- **Realtime Channel (** **`/api/inngest/realtime.ts`** **)** : Defines a typed realtime channel and topic.\n- **Chat Route:** **`/api/chat/route.ts`** : This is a standard Next.js API route. Its only job is to receive a request from the frontend and send an event to Inngest to trigger a function.\n- **Token Route:** **`/api/realtime/token/route.ts`** : This secure endpoint generates a subscription token that the frontend needs to connect to Inngest realtime.\n- **Inngest Route:** **`/api/inngest/route.ts`** : The standard handler that serves all your Inngest functions.\nLet's take a closer look at each of these endpoints and what they do...",
      "char_count": 966,
      "token_count": 242,
      "metadata": {
        "title": "##### Get Started",
        "source": "Docs\\agent_kit\\streaming_usage-guide.md",
        "chunk_method": "hybrid",
        "file_path": "Docs\\agent_kit\\streaming_usage-guide.md",
        "file_name": "streaming_usage-guide.md",
        "file_size": 20969,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "25b5391485f54485ee7b3d3e898d1a3dc75e8faf38caa8ca0a69b2dbd765c0ea",
        "author": null,
        "created_at": "2025-10-12T23:52:24.205018",
        "modified_at": "2025-10-12T23:52:24.205618",
        "page_count": null,
        "word_count": 3442,
        "extracted_at": "2025-10-13T20:00:14.311209",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 242,
        "has_context": true
      }
    },
    {
      "index": 7,
      "text": "Usage Guide\nSet up Inngest for streaming\n1\nInngest Client - /api/inngest/client.ts\nThis file configures the Inngest client and enables the realtime middleware, which is essential for streaming.\nCopy Ask AI\n```\n// app/api/inngest/client.ts\nimport { realtimeMiddleware } from \"@inngest/realtime/middleware\" ;\nimport { Inngest } from \"inngest\" ;\n\nexport const inngest = new Inngest ({\nid: \"agent-app-client\" ,\nmiddleware: [ realtimeMiddleware ()],\n});\n```\n2\nRealtime Channel - /api/inngest/realtime.ts\nHere, we define a strongly-typed channel for our agent's communications. The\n```\nagent_stream\n```\ntopic is where all message chunks will be published fromAgentKit.\nCopy Ask AI\n```\n// app/api/inngest/realtime.ts\nimport { type AgentMessageChunk } from \"@inngest/agent-kit\" ;\nimport { channel , topic } from \"@inngest/realtime\" ;\n\nexport const createChannel = channel (\n( userId : string ) => `user: ${ userId } `\n). addTopic ( topic ( \"agent_stream\" ). type < AgentMessageChunk >());\n```\n3\nChat API Route - /api/chat/route.ts\nThis endpoint is the bridge between your frontend and the Inngest backend. It receives the user's message and dispatches an event to trigger the agent network.\nCopy Ask AI\n```\n// app/api/chat/route.ts\nimport { NextRequest , NextResponse } from \"next/server\" ;\nimport { auth } from \"@clerk/nextjs/server\" ; // Or your auth provider\nimport { z } from \"zod\" ;\nimport { inngest } from \"../inngest/client\" ;\n\nconst chatRequestSchema = z . object ({\nuserMessage: z . object ({\nid: z . string (),\ncontent: z . string (),\nrole: z . literal ( \"user\" ),\n}),\nthreadId: z . string (). optional (),\nchannelKey: z . string (),\n});\n\nexport async function POST ( req : NextRequest ) {\ntry {\nconst { userId } = auth ();\nif ( ! userId ) {\nreturn NextResponse . json ({ error: \"Please sign in\" }, { status: 401 });\n}\n\nconst validationResult = chatRequestSchema . safeParse ( await req . json ());\nif ( ! validationResult . success ) {\nreturn NextResponse . json ({ error: \"Invalid request\" }, { status: 400 });\n}\n\nconst { userMessage , threadId , channelKey } = validationResult . data ;\n\nawait inngest . send ({\nname: \"agent/chat.requested\" ,\ndata: {\nuserMessage ,\nthreadId ,\nchannelKey ,\nuserId ,\n},\n});\n\nreturn NextResponse . json ({ success: true });\n} catch ( error ) {\nreturn NextResponse . json (\n{\nerror: error instanceof Error ? error . message : \"Failed to start chat\" ,\n},\n{ status: 500 }\n);\n}\n}\n```\n4\nToken API Route\n**```\n/api/realtime/token/route.ts\n```**\nThis secure endpoint generates a subscription token that the frontend needs to connect to Inngest realtime.\nCopy Ask AI\n```\nimport { NextRequest , NextResponse } from \"next/server\" ;\nimport { auth } from \"@clerk/nextjs/server\" ; // or any auth provider\nimport { getSubscriptionToken } from \"@inngest/realtime\" ;\n\nimport { inngest } from \"../../inngest/client\" ;\nimport { createChannel } from \"../../inngest/realtime\" ;\n\nexport type RequestBody = {\nuserId ?: string ;\nchannelKey ?: string ;\n};\n\nexport async function POST ( req : NextRequest ) {\nconst { userId } = auth (); // authenticate the user\nif ( ! userId ) {\nreturn NextResponse . json (\n{ error: \"Please sign in to create a token\" },\n{ status: 401 }\n);\n}\n\ntry {\n// 1. Get the channel key from the request body and validate it\nconst { channelKey } = ( await req . json ()) as RequestBody ;\nif ( ! channelKey ) {\nreturn NextResponse . json (\n{ error: \"channelKey is required\" },\n{ status: 400 }\n);\n}\n\n// 2. Create a subscription token for the resolved channel\nconst token = await getSubscriptionToken ( inngest , {\nchannel: createChannel ( channelKey ),\ntopics: [ \"agent_stream\" ],\n});\n\n// 3. Return the token\nreturn NextResponse . json ( token );\n} catch ( error ) {\n// ... handle error response\n}\n}\n```\n5\nInngest Route - /api/inngest/route.ts\nThis is the standard Next.js route handler for serving all of your Inngest functions.\nCopy Ask AI\n```\n// app/api/inngest/route.ts\nimport { serve } from \"inngest/next\" ;\nimport { inngest } from \"./client\" ;\nimport { runAgentNetwork } from \"./functions/run-network\" ;\n\nexport const { GET , POST , PUT } = serve ({\nclient: inngest ,\nfunctions: [ runAgentNetwork ],\n});\n```\nNow that we have Inngest and our API routes configured, let's build out the agents. We are going to create a network of 3 agents orchestrated via a simple code based router. The router will ensure that our network runs the following agents in this exact order:\n1. **Event Matcher** : Selects 1-5 event names that we should consider for the query\n2. **Query Writer** : Generates a SQL query given a list of events & schemas\n3. **Summarizer** : Creates a short summary of the query and adds it to message history\nLet's start by creating our event matcher and query writer agents. Each agent will have access to only one tool each which we will ensure is always invoked by defining a static tool\n_\nchoice.\nCopy Ask AI\n```\nimport { createAgent , createTool , openai } from \"@inngest/agent-kit\" ;\nimport { z } from \"zod\" ;\nimport type { AgentState } from \"./types\" ;\n\n// Define the tool for generating SQL\nexport const generateSqlTool = createTool ({\nname: \"generate_sql\" ,\ndescription: \"Provide the final SQL SELECT statement...\" ,\nparameters: z . object ({\nsql: z . string (). describe ( \"A single valid SELECT statement.\" ),\ntitle: z . string (). describe ( \"Short 20-30 character title for this query\" ),\nreasoning: z . string (). describe ( \"Brief explanation...\" ),\n}),\nhandler : ({ sql , title , reasoning }) => {\nreturn { sql , title , reasoning };\n},\n});\n\n// Define the agent that uses the tool\nexport const queryWriterAgent = createAgent < AgentState >({\nname: \"Insights Query Writer\" ,\ndescription: \"Generates a safe, read-only SQL SELECT statement.\" ,\nsystem : async ({ network }) => {\n/* ... dynamic system prompt ... */\n},\nmodel: openai ({ model: \"gpt-5-nano-2025-08-07\" }),\ntools: [ generateSqlTool ],\ntool_choice: \"generate_sql\" , // Force this tool to be called\n});\n\n// Define the event matcher agent\nexport const selectEventsTool = createTool ({\nname: \"select_events\" ,\ndescription:\n\"Select 1-5 event names from the provided list that are most relevant to the user's query.\" ,\nparameters: z . object ({\nevents: z\n. array (\nz . object ({\nevent_name: z . string (),\nreason: z . string (),\n})\n)\n. min ( 1 )\n. max ( 6 ),\n}),\nhandler : ( args , { network }) => {\nconst { events } = args ;\n\n// Persist selection on network state for downstream agents\nnetwork . state . data . selectedEvents = events ;\n\nreturn {\nselected: events ,\nreason: \"Selected by the LLM based on the user's query.\" ,\ntotalCandidates: network . state . data . eventTypes ?. length || 0 ,\n};\n},\n});\n\nexport const eventMatcherAgent = createAgent < AgentState >({\nname: \"Insights Event Matcher\" ,\ndescription:\n\"Analyzes available events and selects 1-5 that best match the user's intent.\" ,\nsystem : async ({ network }) => {\nconst events = network ?. state . data . eventTypes || [];\nconst sample = events . slice ( 0 , 50 ); // avoid overly long prompts\n\nreturn [\n\"You are an event selection specialist.\" ,\n\"Your job is to analyze the user's request and the list of available event names, then choose the 1-5 most relevant events.\" ,\n\"\" ,\n\"Instructions:\" ,\n\"- Review the list of available events provided below.\" ,\n\"- Based on the user's query, decide which 1-5 events are the best match.\" ,\n\"- Call the `select_events` tool and pass your final choice in the `events` parameter.\" ,\n\"- Do not guess event names; only use names from the provided list.\" ,\n\"\" ,\nsample . length\n? `Available events ( ${\nevents . length\n} total, showing up to 50): \\n ${ sample . join ( \" \\n \" ) } `\n: \"No event list is available. Ask the user to clarify which events they are interested in.\" ,\n]. join ( \" \\n \" );\n},\nmodel: openai ({ model: \"gpt-5-nano-2025-08-07\" }),\ntools: [ selectEventsTool ],\ntool_choice: \"select_events\" , // Force this tool to be called\n});\n```",
      "char_count": 7869,
      "token_count": 2018,
      "metadata": {
        "title": "##### Get Started",
        "source": "Docs\\agent_kit\\streaming_usage-guide.md",
        "chunk_method": "hybrid",
        "file_path": "Docs\\agent_kit\\streaming_usage-guide.md",
        "file_name": "streaming_usage-guide.md",
        "file_size": 20969,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "25b5391485f54485ee7b3d3e898d1a3dc75e8faf38caa8ca0a69b2dbd765c0ea",
        "author": null,
        "created_at": "2025-10-12T23:52:24.205018",
        "modified_at": "2025-10-12T23:52:24.205618",
        "page_count": null,
        "word_count": 3442,
        "extracted_at": "2025-10-13T20:00:14.311209",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 2018,
        "has_context": true
      }
    },
    {
      "index": 8,
      "text": "Usage Guide\nSet up Inngest for streaming\nOnce you have your agent defined, you can define your server-side state type and use\n```\ncreateToolManifest\n```\nto create a type which will be used on the client-side to ensure end-to-end type safety.\nCopy Ask AI\n```\nimport { createToolManifest , type StateData } from \"@inngest/agent-kit\" ;\nimport { selectEventsTool } from \"./event-matcher\" ;\nimport { generateSqlTool } from \"./query-writer\" ;\n\n// server-side state used by networks, routers and agents\nexport type AgentState = StateData & {\nuserId ?: string ;\neventTypes ?: string [];\nschemas ?: Record < string , unknown >;\nselectedEvents ?: { event_name : string ; reason : string }[];\ncurrentQuery ?: string ;\nsql ?: string ;\n};\n\n// a typed manifest of all available tools\nconst manifest = createToolManifest ([\ngenerateSqlTool ,\nselectEventsTool ,\n] as const );\nexport type ToolManifest = typeof manifest ;\n```\nWith server-side state and a ToolManifest now defined, you can strongly type your own agent hook and define client-side state that you may want sent in each message:\nCopy Ask AI\n```\nimport {\nuseAgent ,\ntype AgentKitEvent ,\ntype UseAgentsConfig ,\ntype UseAgentsReturn ,\n} from \"@inngest/use-agent\" ;\n\nimport type { ToolManifest } from \"@/app/api/inngest/functions/agents/types\" ;\n\nexport type ClientState = {\nsqlQuery : string ;\neventTypes : string [];\nschemas : Record < string , unknown > | null ;\ncurrentQuery : string ;\n};\n\nexport type AgentConfig = { tools : ToolManifest ; state : ClientState };\n\nexport type AgentEvent = AgentKitEvent < ToolManifest >;\n\nexport function useInsightsAgent (\nconfig : UseAgentsConfig < ToolManifest , ClientState >\n) : UseAgentsReturn < ToolManifest , ClientState > {\nreturn useAgent <{ tools : ToolManifest ; state : ClientState }>( config );\n}\n```\nBefore we move onto implementing the agent hook into your UI components, let's create a summarizer agent and an agent network with a code-based router to orchestrate everything:\nCopy Ask AI\n```\n// Define the summarizer agent - this agent has no tools and just provides a summary\nexport const summarizerAgent = createAgent < AgentState >({\nname: \"Insights Summarizer\" ,\ndescription:\n\"Writes a concise summary describing what the generated SQL does and why.\" ,\nsystem : async ({ network }) => {\nconst events =\nnetwork ?. state . data . selectedEvents ?. map (( e ) => e . event_name ) ?? [];\nconst sql = network ?. state . data . sql ;\n\nreturn [\n\"You are a helpful assistant summarizing the result of a SQL generation process.\" ,\n\"Write a one sentence short summary that explains:\" ,\n\"- What events were just analyzed (if known).\" ,\n\"- What the query returns and how it helps the user.\" ,\n\"Avoid restating the full SQL. Be clear and non-technical when possible.\" ,\nevents . length ? `Selected events: ${ events . join ( \", \" ) } ` : \"\" ,\nsql\n? \"A SQL statement has been prepared; summarize its intent, not its exact text.\"\n: \"\" ,\n]\n. filter ( Boolean )\n. join ( \" \\n \" );\n},\nmodel: openai ({ model: \"gpt-5-nano-2025-08-07\" }),\n});\n```\nCopy Ask AI\n```\n// app/api/inngest/functions/agents/network.ts\n\nimport { createNetwork , openai , type Network } from \"@inngest/agent-kit\" ;\nimport { eventMatcherAgent } from \"./event-matcher\" ;\nimport { queryWriterAgent } from \"./query-writer\" ;\nimport { summarizerAgent } from \"./summarizer\" ;\nimport type { InsightsAgentState } from \"./types\" ;\n\n// A simple router that executes agents in a fixed order\nconst sequenceRouter : Network . Router < InsightsAgentState > = async ({\ncallCount ,\n}) => {\nif ( callCount === 0 ) return eventMatcherAgent ;\nif ( callCount === 1 ) return queryWriterAgent ;\nif ( callCount === 2 ) return summarizerAgent ;\nreturn undefined ; // ends the network run\n};\n\n// Define the network directly - no factory function needed\nexport const insightsNetwork = createNetwork < InsightsAgentState >({\nname: \"Insights SQL Generation Network\" ,\ndescription:\n\"Selects relevant events, proposes a SQL query, and summarizes the result.\" ,\nagents: [ eventMatcherAgent , queryWriterAgent , summarizerAgent ],\ndefaultModel: openai ({ model: \"gpt-5-nano-2025-08-07\" }),\nmaxIter: 6 ,\nrouter: sequenceRouter ,\n});\n```\nNow let's create an Inngest function which we'll use to run our agent network and configure event streaming:\nCopy Ask AI\n```\n// app/api/inngest/functions/run-network.ts\nimport {\ncreateState ,\ntype AgentMessageChunk ,\ntype Message ,\n} from \"@inngest/agent-kit\" ;\nimport type { ChatRequestEvent } from \"@inngest/use-agent\" ;\nimport { v4 as uuidv4 } from \"uuid\" ;\n\nimport { inngest } from \"../client\" ;\nimport { createChannel } from \"../realtime\" ;\nimport type { InsightsAgentState } from \"./agents/types\" ;\nimport { insightsNetwork } from \"./agents/network\" ;\n\nexport const runAgentNetwork = inngest . createFunction (\n{\nid: \"run-insights-agent\" ,\nname: \"Insights SQL Agent\" ,\n},\n{ event: \"insights-agent/chat.requested\" },\nasync ({ event , publish , step }) => {\nconst {\nthreadId : providedThreadId ,\nuserMessage , // new user message\nuserId ,\nchannelKey , // channel to stream on\nhistory , // previous messages\n} = event . data as ChatRequestEvent ;\n\n// Validate required userId\nif ( ! userId ) {\nthrow new Error ( \"userId is required for agent chat execution\" );\n}\n\n// Generate a threadId\nconst threadId = await step . run ( \"generate-thread-id\" , async () => {\nreturn providedThreadId || uuidv4 ();\n});\n\n// Determine the target channel for publishing (channelKey takes priority)\nconst targetChannel = await step . run (\n\"generate-target-channel\" ,\nasync () => {\nreturn channelKey || userId ;\n}\n);\n\ntry {\nconst clientState = userMessage . state || {};\n\n// Create state for the network\nconst networkState = createState < InsightsAgentState >(\n{\nuserId ,\n... clientState , // passing in client-side managed state into our network\n},\n{\nmessages: history ,\nthreadId ,\n}\n);\n\n// Run the network with streaming enabled\nawait insightsNetwork . run ( userMessage , {\nstate: networkState ,\nstreaming: {\npublish : async ( chunk : AgentMessageChunk ) => {\n// you can inspect and add metadata to chunks here\nawait publish ( createChannel ( targetChannel ). agent_stream ( chunk ));\n},\n},\n});\n\nreturn {\nsuccess: true ,\nthreadId ,\nmessage: \"Agent network completed successfully\" ,\n};\n} catch ( error ) {\n// emit an error chunk here\n}\n}\n);\n```\nWith all that wired up now, you can now render tool calls and messages in your UI like so:\nCopy Ask AI",
      "char_count": 6389,
      "token_count": 1522,
      "metadata": {
        "title": "##### Get Started",
        "source": "Docs\\agent_kit\\streaming_usage-guide.md",
        "chunk_method": "hybrid",
        "file_path": "Docs\\agent_kit\\streaming_usage-guide.md",
        "file_name": "streaming_usage-guide.md",
        "file_size": 20969,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "25b5391485f54485ee7b3d3e898d1a3dc75e8faf38caa8ca0a69b2dbd765c0ea",
        "author": null,
        "created_at": "2025-10-12T23:52:24.205018",
        "modified_at": "2025-10-12T23:52:24.205618",
        "page_count": null,
        "word_count": 3442,
        "extracted_at": "2025-10-13T20:00:14.311209",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 1522,
        "has_context": true
      }
    },
    {
      "index": 9,
      "text": "Usage Guide\nSet up Inngest for streaming\n```\n\"use client\" ;\n\nimport { useState } from \"react\" ;\nimport { useInsightsAgent , type ClientState } from \"@/lib/use-insights-agent\" ;\nimport type { ToolCallUIPart } from \"@inngest/use-agent\" ;\nimport type { ToolManifest } from \"@/app/api/inngest/functions/agents/types\" ;\n\nexport default function ChatTestPage () {\nreturn (\n< div >\n< p > Minimal example using a single-threaded conversation. </ p >\n< Chat />\n</ div >\n);\n}\n\nfunction Chat () {\nconst [ input , setInput ] = useState ( \"\" );\nconst { messages , status , sendMessage } = useInsightsAgent ({\nchannelKey: \"chat_test\" ,\nstate : () : ClientState => ({\neventTypes: [\n\"app/user.created\" ,\n\"order.created\" ,\n\"payment.failed\" ,\n\"email.sent\" ,\n],\nschemas: null ,\ncurrentQuery: \"\" ,\ntabTitle: \"Chat Test\" ,\nmode: \"demo\" ,\ntimestamp: Date . now (),\n}),\n});\n\nasync function onSubmit ( e : React . FormEvent ) {\ne . preventDefault ();\nconst value = input . trim ();\nif ( ! value || status !== \"ready\" ) return ;\nsetInput ( \"\" );\nawait sendMessage ( value );\n}\n\nreturn (\n< div >\n< div >\n{ messages . map (({ id , role , parts }) => (\n< div key = { id } >\n< div > { role } </ div >\n{ parts . map (( part ) => {\nif ( part . type === \"text\" ) {\nreturn < div key = { part . id } > { part . content } </ div > ;\n}\nif ( part . type === \"tool-call\" ) {\nreturn < ToolCallRenderer key = { part . toolCallId } part = { part } /> ;\n}\nreturn null ;\n}) }\n</ div >\n)) }\n\n{ status !== \"ready\" && < p > AI is thinking... </ p > }\n</ div >\n\n< form onSubmit = { onSubmit } >\n< input\nvalue = { input }\nonChange = { ( e ) => setInput ( e . target . value ) }\nplaceholder = { status === \"ready\" ? \"Ask me anything\" : \"Thinking...\" }\ndisabled = { status !== \"ready\" }\n/>\n< button type = \"submit\" disabled = { status !== \"ready\" } >\nSend\n</ button >\n</ form >\n</ div >\n);\n}\n\nfunction ToolCallRenderer ({ part } : { part : ToolCallUIPart < ToolManifest > }) {\nif ( part . state !== \"output-available\" ) return null ;\n\nif ( part . toolName === \"select_events\" ) {\nconst { data } = part . output ;\nreturn (\n< div >\n< div > Selected Events: </ div >\n< ul >\n{ data . selected . map (( e ) => (\n< li key = { e . event_name } >\n< p > { e . event_name } </ p >\n< p > { e . reason } </ p >\n</ li >\n)) }\n</ ul >\n</ div >\n);\n}\n\nif ( part . toolName === \"generate_sql\" ) {\nconst { data } = part . output ;\nreturn (\n< div >\n< div > SQL Query: </ div >\n< p > { data . title } </ p >\n< p > { data . reasoning } </ p >\n< pre > { data . sql } </ pre >\n</ div >\n);\n}\n\nreturn null ;\n}\n```\nWith all that done, you should now have a fully functional SQL generation agent network with realtime streaming!\nBy following this guide and using the\n```\nuseAgent\n```\nhook, you now have:\n1. **Type Safety** : Tool names, inputs, and outputs are fully typed based on your `ToolManifest`\n2. **Real-time Streaming** : See tools execute in real-time with different states ( `input-streaming` , `input-available` , `executing` , `output-available` )\n3. **Generative UI** : Each tool can have its own custom rendering logic while maintaining type safety\n4. **State Management** : The hook automatically manages conversation state, message ordering, and streaming events\n5. **Error Handling** : Built-in error states and recovery mechanisms\n[Overview Previous](\\streaming\\overview)\n[Events Next](\\streaming\\events)\nâŒ˜ I\nAssistant Responses are generated using AI and may contain mistakes.",
      "char_count": 3418,
      "token_count": 912,
      "metadata": {
        "title": "##### Get Started",
        "source": "Docs\\agent_kit\\streaming_usage-guide.md",
        "chunk_method": "hybrid",
        "file_path": "Docs\\agent_kit\\streaming_usage-guide.md",
        "file_name": "streaming_usage-guide.md",
        "file_size": 20969,
        "file_format": ".md",
        "mime_type": "text/markdown",
        "sha256_hash": "25b5391485f54485ee7b3d3e898d1a3dc75e8faf38caa8ca0a69b2dbd765c0ea",
        "author": null,
        "created_at": "2025-10-12T23:52:24.205018",
        "modified_at": "2025-10-12T23:52:24.205618",
        "page_count": null,
        "word_count": 3442,
        "extracted_at": "2025-10-13T20:00:14.311209",
        "processing_method": "markdown_docling",
        "custom_metadata": {},
        "total_chunks": 10,
        "token_count": 912,
        "has_context": true
      }
    }
  ]
}